{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Generate captions for images using default beam search parameters.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import os\n",
    "from os import listdir, path\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageOps\n",
    "import PIL.ImageFont\n",
    "import PIL.ImageDraw\n",
    "import textwrap\n",
    "from io import BytesIO\n",
    "\n",
    "from im2txt import configuration\n",
    "from im2txt import inference_wrapper\n",
    "from im2txt.inference_utils import caption_generator\n",
    "from im2txt.inference_utils import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "INFO:tensorflow:Initializing vocabulary from file: C:/Users/win8/Documents/PF/im2txt/data/mscoco/word_counts3.txt\n",
      "INFO:tensorflow:Created vocabulary with 11520 words\n",
      "INFO:tensorflow:Loading model from checkpoint: C:/Users/win8/Documents/PF/im2txt/model/train/model.ckpt-3000000\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-3000000\n"
     ]
    }
   ],
   "source": [
    "# Choose the trained model (2 or 3)\n",
    "model_number = \"3\"\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Build the inference graph.\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(configuration.ModelConfig(), \"C:/Users/win8/Documents/PF/im2txt/model/train/model.ckpt-\"+model_number+\"000000\")\n",
    "g.finalize()\n",
    "\n",
    "# Create the vocabulary.\n",
    "vocab = vocabulary.Vocabulary(\"C:/Users/win8/Documents/PF/im2txt/data/mscoco/word_counts\"+model_number+\".txt\") \n",
    "\n",
    "sess = tf.Session(graph=g)\n",
    "# Load the model from checkpoint.\n",
    "restore_fn(sess)\n",
    "\n",
    "# Prepare the caption generator. Here we are implicitly using the default\n",
    "# beam search parameters. See caption_generator.py for a description of the\n",
    "# available beam search parameters.\n",
    "generator = caption_generator.CaptionGenerator(model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./imagenes/1.jpg\n",
      "  0) two elephants standing next to each other in a zoo . (p=0.001062)\n",
      "  1) a baby elephant standing next to an adult elephant . (p=0.001054)\n",
      "  2) two elephants standing next to each other on a dirt ground . (p=0.000412)\n",
      "./imagenes/2.jpg\n",
      "  0) a large elephant standing next to a baby elephant . (p=0.000386)\n",
      "  1) a large elephant standing next to a tree . (p=0.000297)\n",
      "  2) an elephant standing in the middle of a dirt road . (p=0.000161)\n",
      "./imagenes/3.jpg\n",
      "  0) a group of people riding on the backs of elephants . (p=0.005613)\n",
      "  1) a group of people riding on the back of an elephant . (p=0.004426)\n",
      "  2) a group of people riding on top of an elephant . (p=0.004155)\n",
      "./imagenes/4.jpg\n",
      "  0) a herd of elephants walking across a dirt field . (p=0.003572)\n",
      "  1) a herd of elephants walking across a dirt road . (p=0.002262)\n",
      "  2) a herd of elephants walking along a dirt road . (p=0.002113)\n",
      "./imagenes/5.jpg\n",
      "  0) a herd of elephants walking across a river . (p=0.004439)\n",
      "  1) a herd of elephants standing in a river . (p=0.001416)\n",
      "  2) a herd of elephants standing in a river (p=0.000164)\n",
      "./imagenes/6.jpg\n",
      "  0) a group of elephants standing next to each other . (p=0.007607)\n",
      "  1) a group of elephants that are standing in the dirt . (p=0.001832)\n",
      "  2) a group of elephants standing next to each other in a zoo . (p=0.000167)\n",
      "./imagenes/Elefante_carga.jpg\n",
      "  0) a man riding on the back of an elephant . (p=0.011378)\n",
      "  1) two people riding on the back of an elephant . (p=0.004964)\n",
      "  2) two people riding on the back of an elephant (p=0.003058)\n",
      "./imagenes/Elefante_con_mama.jpg\n",
      "  0) two adult elephants and a baby elephant walking through a field . (p=0.000040)\n",
      "  1) two adult elephants and one baby elephant walking through the woods . (p=0.000033)\n",
      "  2) two adult elephants and a baby elephant walking through a grassy area . (p=0.000024)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./imagenes/\"\n",
    "filenames = listdir(image_path)\n",
    "font = PIL.ImageFont.truetype(\"./fonts/Aaargh.ttf\", 16)\n",
    "\n",
    "for file in filenames:\n",
    "    try:\n",
    "        print(image_path+file)\n",
    "        img = PIL.Image.open(image_path+file).convert('RGBA')\n",
    "        box = PIL.Image.new('RGBA', img.size, (255,255,255,0))\n",
    "        draw = PIL.ImageDraw.Draw(box)\n",
    "        \n",
    "        image = open(image_path+file,'rb').read()\n",
    "        captions = generator.beam_search(sess, image)\n",
    "        for i, caption in enumerate(captions):\n",
    "            # Ignore begin and end words.\n",
    "            sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            sentence = \" \".join(sentence)\n",
    "            print(\"  %d) %s (p=%f)\" % (i, sentence, math.exp(caption.logprob)))\n",
    "            if i==0:\n",
    "                margin = offset = offset_a = 0\n",
    "                for line in textwrap.wrap(sentence, width=52):\n",
    "                    offset_a = offset\n",
    "                    offset += font.getsize(line)[1]\n",
    "                    draw.rectangle(((0, offset_a), (img.size[0], offset)), fill=(0,0,0,128))\n",
    "                    draw.text((margin, offset_a), line, (255,255,255),font=font)\n",
    "                out = PIL.Image.alpha_composite(img, box)\n",
    "                out.show()\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
